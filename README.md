# AstrBot 上下文裁剪器插件 (astrbot_plugin_ctx_trimmer)

这是一个用于 AstrBot 的插件，旨在智能管理大型语言模型 (LLM) 的上下文，通过裁剪旧的对话轮次来控制输入 token 数量，从而优化成本并提高模型效率。

## 功能特性

*   **基于 Token 的智能裁剪**: 在每次 LLM 请求前，根据配置的最大 token 限制，自动裁剪对话历史。
*   **保留系统提示词**: 确保重要的系统提示词不会被裁剪，维持模型的行为一致性。
*   **按对话轮次丢弃**: 以用户发言为单位，每次丢弃指定数量的最早对话轮次，保持对话的连贯性。
*   **可配置的参数**: 允许用户通过命令或配置文件调整裁剪行为。
*   **兼容 OpenAI 风格计数**: 近似支持 OpenAI 风格的 token 计数，并可选择使用 `tiktoken` 进行更精确的计数。
*   **中英文命令支持**: 提供 `/ctxlimit` 和 `/上下文` 两种命令前缀，方便用户操作。

## 安装

1.  确保您的 AstrBot 环境已正确设置。
2.  将此插件放置在 AstrBot 的插件目录中。
3.  安装必要的依赖：
    ```bash
    pip install -r requirements.txt
    ```

## 配置

插件的配置可以通过 `_conf_schema.json` 文件进行管理，也可以通过 AstrBot 的配置界面进行调整。

| 配置项           | 类型   | 默认值 | 描述                                     |
| :--------------- | :----- | :----- | :--------------------------------------- |
| `启用`           | `bool` | `true` | 是否启用上下文裁剪功能                   |
| `最大上下文token` | `int`  | `8192` | LLM 输入的最大 token 限制（不含输出余量） |
| `每次丢弃的对话轮数` | `int`  | `2`    | 每次裁剪时丢弃的最早对话轮次数量         |
| `输出保留余量token` | `int`  | `512`  | 为 LLM 输出预留的 token 数量             |
| `计数模型提示`   | `string` | `""`   | 用于 `tiktoken` 计数的模型名提示（留空自动） |

## 使用

插件启用后，它会在每次 LLM 请求前自动检查并裁剪上下文。您也可以通过以下命令进行手动管理：

### 命令 (英文)

*   `/ctxlimit status`: 查看当前上下文裁剪器的配置状态。
*   `/ctxlimit enable`: 启用上下文裁剪功能。
*   `/ctxlimit disable`: 停用上下文裁剪功能。
*   `/ctxlimit setmax <max_tokens>`: 设置最大上下文 token 数量。
*   `/ctxlimit setdrop <turns>`: 设置每次丢弃的对话轮数。
*   `/ctxlimit setmargin <margin>`: 设置输出保留余量 token 数量。

### 命令 (中文别名)

*   `/上下文 状态`: 查看当前上下文裁剪器的配置状态。
*   `/上下文 启用`: 启用上下文裁剪功能。
*   `/上下文 停用`: 停用上下文裁剪功能。
*   `/上下文 设最大 <最大>`: 设置最大上下文 token 数量。
*   `/上下文 设丢弃 <轮数>`: 设置每次丢弃的对话轮数。
*   `/上下文 设余量 <余量>`: 设置输出保留余量 token 数量。

## 依赖

*   `tiktoken`: (可选) 用于更精确的 OpenAI 风格 token 计数。如果未安装，插件将使用粗略估算。

## 许可证

本项目采用 MIT 许可证。
